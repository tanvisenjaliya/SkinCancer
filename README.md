## Skin Cancer MNIST: HAM10000
### A large collection of multi-source dermatoscopic images of pigmented lesions
#### DataSource : https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000
The small size and lack of diversity of the available dataset of dermatoscopic pictures make it difficult to train neural networks for automated identification of pigmented skin lesions. The HAM10000 ("Human Against Machine with 10000 training images") dataset addresses this issue. It consist of  dermatoscopic images from various populations, which were captured and preserved using various modalities. There are 10015 dermatoscopic images in the final dataset, which can be used as a training set for academic machine learning. The cases include a diverse range of pigmented lesions, including actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv) and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file. The International Skin Imaging Collaboration (ISIC), a multinational partnership that has created the world's biggest public archive of dermoscopic pictures of skin, held the world's largest skin image analysis challenge. In 2018, the challenge was held in Granada, Spain, at the Medical Image Computing and Computer Assisted Intervention conference. Over 12,500 photos were included in the dataset, which was divided into three jobs. 900 individuals signed up for data download, with 115 completing the lesion segmentation job, 25 the lesion attribute detection task, and 159 the illness classification task

### Background: 
It's questionable whether machine-learning algorithms can reliably diagnose all pigmented skin lesions as well as human experts. The goal of this study was to see how well state-of-the-art machine-learning algorithms compared to human readers for all clinically important forms of benign and malignant pigmented skin lesions.
### Methods: 
Human readers were asked to identify dermatoscopic photos randomly picked in 30-image batches from a test set of 1511 images for this open, web-based, multinational diagnostic investigation. Human readers' diagnoses were compared against 139 algorithms developed by 77 machine-learning labs who took part in the International Skin Imaging Collaboration 2018 challenge and were given a training set of 10015 photos ahead of time.  The differences in the number of correct specific diagnoses each batch were the two key outcomes.
### Findings: 
511 human readers from 63 countries had at least one attempt in the reader study. 283 of 511 human readers were board-certified dermatologists, 118 were dermatology residents, and 83 were general practitioners. When comparing all human readers with all machine-learning algorithms, the algorithms achieved a mean of 2·01 more correct diagnoses . 27 human experts with more than 10 years of experience achieved a mean of 18·78 correct answers, compared with 25·43 correct answers for the top three machine algorithms. The difference between human experts and the top three algorithms was significantly lower for images in the test set that were collected from sources not included in the training set .
### File 1: skincancer_1.ipynb
here a simple convolution neural network is built. 

Architecture: input-->(convo2d --> maxpooling2d)x3-->dropout--> convo2d --> maxpooling2d -->dropout --> flatten -->Dense --> Output
